

=== Content of /home/sam/github/finance-data-driven/config/train_config.yaml ===

path_experiments_storage: "/home/sam/github/finance-data-driven/data/experiments_storage"

xgboost:
  learning_rate: 0.1
  max_depth: 6
  n_estimators: 100

random_forest:
  n_estimators: 100
  max_depth: None
  min_samples_split: 2

validation_method: 'comb_purged_kfold'  # Can be 'kfold', 'stratified_kfold', or 'comb_purged_kfold'




=== Content of /home/sam/github/finance-data-driven/mlops/model_training/model_validation.py ===

import itertools as itt
import numbers
import numpy as np
import pandas as pd

from abc import abstractmethod
from typing import Iterable, Tuple, List

class BaseTimeSeriesCrossValidator:
    ...
  


class CombPurgedKFoldCV(BaseTimeSeriesCrossValidator):
    ...

=== Content of /home/sam/github/finance-data-driven/mlops/model_training/train_model.py ===


import yaml
import sys
import pandas as pd
import mlflow
import optuna
from sklearn.model_selection import KFold, StratifiedKFold
from xgboost import XGBClassifier
from dotenv import load_dotenv
from model_validation import CombPurgedKFoldCV
import warnings

# Suppress warnings
warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings('ignore', category=UserWarning)

# Load environment variables
load_dotenv()

# Function to load configuration
def load_config(path):
    try:
        with open(path, 'r') as f:
            return yaml.safe_load(f)
    except FileNotFoundError:
        print(f"Configuration file {path} not found. Exiting.")
        sys.exit()

# Function to load dataset
def load_dataset(path):
    try:
        return pd.read_csv(path)
    except FileNotFoundError:
        print(f"Data file {path} not found. Exiting.")
        sys.exit()

import os

# Function to ensure the directory exists or create it
def ensure_directory_exists(directory):
    if not os.path.exists(directory):
        os.makedirs(directory)
        print(f"Directory {directory} created.")
    else:
        print(f"Directory {directory} already exists.")





# Initialize configurations
config = load_config("../../config/train_config.yaml")

# Directory from configuration and database path
path_experiments_storage = config['path_experiments_storage']

# Ensure directory exists
ensure_directory_exists(path_experiments_storage)


db_path = os.path.join(path_experiments_storage, "optuna.db")
mlflow_artifact_location = os.path.join(path_experiments_storage, "mlruns")

mlflow.set_tracking_uri(mlflow_artifact_location)
mlflow.set_experiment(config.get('experiment_name', 'Default_Experiment2'))
# Initialize Optuna
try:
    study = optuna.create_study(
        study_name=config.get('study_name', 'Default_Study_Name'),
        storage=f"sqlite:///{db_path}",
        direction="maximize",
        load_if_exists=True
    )
    print("Optuna study created.")
except Exception as e:
    print(f"Could not initialize Optuna study. Error: {e}")

# Load and prepare dataset
df_train = load_dataset('/home/sam/github/finance-data-driven/data/processed/synthetic_ticker_data.csv')
cols_feat = [c for c in df_train.columns if c not in ['datetime', 'target', 'ticker']]
X = df_train[cols_feat]
y = df_train['target']

# Re-map target values
y = y.map({-1: 0, 0: 1, 1: 2})

# Initialize Cross-Validation
cv_method = config.get('validation_method', 'kfold')
splits = []

if cv_method == 'comb_purged_kfold':
    cv = CombPurgedKFoldCV(n_splits=3, n_test_splits=1, embargo_td=2)
    t1_ = df_train.index
    t1 = pd.Series(t1_).shift(100).fillna(0).astype(int)
    t2 = pd.Series(t1_).shift(-100).fillna(1e12).astype(int)
    splits = list(cv.split(df_train, pred_times=t1, eval_times=t2))
elif cv_method == 'kfold':
    cv = KFold(n_splits=5)
elif cv_method == 'stratified_kfold':
    cv = StratifiedKFold(n_splits=5)
else:
    print(f"Invalid cross-validation method: {cv_method}. Exiting.")
    sys.exit()



# Objective function for Optuna optimization
def objective(trial):
    with mlflow.start_run() as run:
        n_estimators = trial.suggest_int("n_estimators", 50, 200)
        max_depth = trial.suggest_int("max_depth", 2, 32, log=True)
        
        model = XGBClassifier(n_estimators=n_estimators, max_depth=max_depth)
        
        cv_scores = []
        for train_index, test_index in splits:
            X_train, X_test = X.iloc[train_index], X.iloc[test_index]
            y_train, y_test = y.iloc[train_index], y.iloc[test_index]
            
            model.fit(X_train, y_train)
            score = model.score(X_test, y_test)
            cv_scores.append(score)
        
        avg_score = sum(cv_scores) / len(cv_scores)
        
        mlflow.log_params({'n_estimators': n_estimators, 'max_depth': max_depth})
        mlflow.log_metric('cv_score', avg_score)
        
        return avg_score

# Optimize
study.optimize(objective, n_trials=config.get('n_trials', 10))

# Save the best parameters
best_params = study.best_params
with open("../config/best_params.yaml", 'w') as f:
    yaml.dump(best_params, f)
