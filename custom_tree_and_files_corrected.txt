/home/sam/github/data-driven-investor-platform
├── :
├── data
├── data_pipeline
│   ├── common
│   │   ├── config.py
│   │   └── constants.py
│   ├── database
│   │   ├── database_session.py
│   │   ├── models
│   │   │   └── financial_statements.py
│   │   └── utils
│   ├── fetch_data
│   │   └── fetch_equities.py
│   ├── investorkit
│   │   ├── environment.yml
│   │   ├── .gitignore
│   │   ├── investorkit
│   │   │   └── get_data
│   │   │       └── base.py
│   │   ├── LICENSE
│   │   ├── README.md
│   │   └── requirements.txt
│   ├── main.py
│   ├── monitoring
│   │   └── prometheus_metrics.py
│   ├── setup_database.py
│   └── utils
│       ├── context_manager.py
│       └── process_data.py
├── directory
├── .env
├── file
├── .gitignore
├── LICENSE
├── my_log_file.log
├── no
├── or
└── README.md

18 directories, 21 files


=== Content of /home/sam/github/data-driven-investor-platform/data_pipeline/main.py ===

# Existing imports...
from fetch_data.fetch_equities import (
    fetch_and_store_profiles,
    fetch_and_store_financial_statements,
)
from database.database_session import SessionLocal, engine
from common.config import FMP_API_KEY, HTTP_PORT
from prometheus_client import start_http_server
import logging

# Initialize logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

if __name__ == "__main__":
    try:
        # Starting HTTP server for metrics
        start_http_server(HTTP_PORT)
        logger.info(f"HTTP server started on port {HTTP_PORT}")

        fetch_and_store_profiles(engine, FMP_API_KEY, SessionLocal)
        fetch_and_store_financial_statements(engine, FMP_API_KEY, SessionLocal)

    except Exception as e:
        logger.exception(f"An error occurred: {e}")


=== Content of /home/sam/github/data-driven-investor-platform/data_pipeline/setup_database.py ===

from sqlalchemy import create_engine
from database.models.financial_statements import Base
from data_pipeline.common.config import (
    DATABASE_URL,
)  # Import from the consolidated config file

engine = create_engine(DATABASE_URL)


def setup_database():
    Base.metadata.create_all(bind=engine)


if __name__ == "__main__":
    setup_database()


=== Content of /home/sam/github/data-driven-investor-platform/data_pipeline/utils/process_data.py ===

# Existing imports...
import numpy as np
import pandas as pd
from common.constants import MIN_BIGINT, MAX_BIGINT
import logging

logger = logging.getLogger(__name__)


def filter_bigint_range(df: pd.DataFrame) -> pd.DataFrame:
    try:
        min_bigint, max_bigint = MIN_BIGINT, MAX_BIGINT
        numeric_cols = df.select_dtypes(include=[np.number]).columns

        for col in numeric_cols:
            df = df.query(f"{min_bigint} <= {col} <= {max_bigint}")

        logger.info(f"Filtered DataFrame based on the bigint range.")
        return df

    except Exception as e:
        logger.exception(f"An error occurred while filtering DataFrame: {e}")
        return pd.DataFrame()


=== Content of /home/sam/github/data-driven-investor-platform/data_pipeline/utils/context_manager.py ===

from contextlib import contextmanager
from sqlalchemy.orm import sessionmaker


@contextmanager
def session_scope(SessionLocal):
    """Provide a transactional scope around a series of operations."""
    session = SessionLocal()
    try:
        yield session
        session.commit()
    except:
        session.rollback()
        raise
    finally:
        session.close()


=== Content of /home/sam/github/data-driven-investor-platform/data_pipeline/monitoring/prometheus_metrics.py ===

from prometheus_client import Summary, Counter, Gauge
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

try:
    EXECUTION_TIME = Summary("function_execution_seconds", "Time spent processing.")
    NEW_SYMBOLS = Counter(
        "new_symbols_fetched", "Number of new symbols fetched.", ["run_id"]
    )
    SYMBOLS_LENGTH = Gauge(
        "symbols_length", "Length of the list of symbols fetched.", ["run_id"]
    )
    TOTAL_RECORDS = Gauge(
        "total_records", "Total number of records in the profiles table.", ["run_id"]
    )
    FETCH_PARAMS = Gauge(
        "fetch_params",
        "Parameters passed to fetch_equity_symbols",
        ["country", "market", "run_id"],
    )
    MISSING_SYMBOLS = Counter(
        "missing_symbols_fetched", "Number of missing new symbols.", ["run_id"]
    )
    logger.info("Successfully initialized Prometheus metrics.")
except Exception as e:
    logger.error(f"Failed to initialize Prometheus metrics: {e}")


=== Content of /home/sam/github/data-driven-investor-platform/data_pipeline/investorkit/investorkit/get_data/base.py ===

from typing import Union, List, Tuple
import pandas as pd
import numpy as np
import logging

# Initialize logging
logging.basicConfig(level=logging.WARNING)

try:
    from tqdm import tqdm

    ENABLE_TQDM = True
except ImportError:
    ENABLE_TQDM = False

### Useful for debug
# tickers=list(df['symbol'])
# statement="cashflow"
# api_key=FMP_API_KEY
# quarter = True
# start_date="2000-01-01"
# end_date=None
# rounding = 4
# progress_bar = True


def get_financial_statements(
    tickers: Union[str, List[str]],
    statement: str = "",
    api_key: str = "",
    quarter: bool = True,
    start_date: Union[str, None] = None,
    end_date: Union[str, None] = None,
    rounding: Union[int, None] = 4,
    progress_bar: bool = True,
) -> Tuple[pd.DataFrame, List[str]]:
    """
    Retrieves financial statements for one or multiple companies and returns a DataFrame.

    Args:
        tickers: List of company tickers.
        statement: Type of financial statement ("balance", "income", or "cashflow").
        api_key: API key for financial data provider.
        quarter: Whether to retrieve quarterly data.
        start_date: Start date to filter data.
        end_date: End date to filter data.
        rounding: Rounding precision.
        progress_bar: Show progress bar for more than 10 tickers.

    Returns:
        Tuple containing the DataFrame of financial statements and a list of invalid tickers.

    Example:

        df, invalid_tickers = get_financial_statements(
            tickers=["AAPL", "META"],
            statement="cashflow",
            api_key="your_api_key_here",
            start_date="2000-01-01"
        )
    """

    # Ensure tickers is a list
    if not isinstance(tickers, (list, str)):
        raise ValueError(f"Invalid type for tickers: {type(tickers)}")

    ticker_list = tickers if isinstance(tickers, list) else [tickers]

    statement_to_location = {
        "balance": "balance-sheet-statement",
        "income": "income-statement",
        "cashflow": "cash-flow-statement",
    }

    location = statement_to_location.get(statement)
    if location is None:
        raise ValueError(
            "Invalid statement type. Choose 'balance', 'income', or 'cashflow'."
        )

    period = "quarter" if quarter else "annual"

    financial_statement_dict = {}
    invalid_tickers = []

    ticker_iterator = (
        tqdm(ticker_list, desc=f"Obtaining {statement} data")
        if ENABLE_TQDM & progress_bar
        else ticker_list
    )

    for ticker in ticker_iterator:
        url = f"https://financialmodelingprep.com/api/v3/{location}/{ticker}?period={period}&apikey={api_key}"

        try:
            financial_statement = pd.read_json(url)
            if financial_statement.empty:
                logging.warning(f"Received empty data for {ticker}")
                invalid_tickers.append(ticker)
                continue

        except Exception as error:
            # logging.warning(f"Could not fetch data for {ticker}. Error: {error}")
            invalid_tickers.append(ticker)
            continue

        # Convert date to appropriate format
        date_col = "date" if quarter else "calendarYear"
        freq = "Q" if quarter else "Y"
        financial_statement[date_col] = pd.to_datetime(
            financial_statement[date_col].astype(str)
        ).dt.to_period(freq)

        financial_statement_dict[ticker] = financial_statement

    if not financial_statement_dict:
        return pd.DataFrame(), invalid_tickers

    financial_statement_total = pd.concat(financial_statement_dict)

    financial_statement_total.reset_index(drop=True, inplace=True)
    financial_statement_total = financial_statement_total.drop_duplicates().reset_index(
        drop=True
    )

    if start_date or end_date:
        mask = True
        if start_date:
            mask &= financial_statement_total["date"] >= start_date
        if end_date:
            mask &= financial_statement_total["date"] <= end_date
        financial_statement_total = financial_statement_total[mask]

    financial_statement_total["date"] = financial_statement_total["date"].astype(str)
    return financial_statement_total, invalid_tickers


def get_profile(tickers, api_key):
    """
    Description
    ----
    Gives information about the profile of a company which includes
    i.a. beta, company description, industry, and sector.

    Parameters
    ----
    tickers : list or str
        The company tickers (e.g., "AAPL" or ["AAPL", "GOOGL"]).
    api_key : str
        The API Key obtained from Financial Modeling Prep.

    Returns
    ----
    pd.DataFrame
        Data with variables in rows and tickers in columns.
    """
    # Ensure tickers is a list
    if not isinstance(tickers, (list, str)):
        raise ValueError(f"Type for the tickers ({type(tickers)}) variable is invalid.")

    tickers = tickers if isinstance(tickers, list) else [tickers]

    profiles = {}
    for ticker in tqdm(tickers):
        try:
            data = pd.read_json(
                f"https://financialmodelingprep.com/api/v3/profile/{ticker}?apikey={api_key}"
            )
            profiles[ticker] = data
        except Exception as error:
            print(f"Warning: Could not fetch data for {ticker}. Error: {error}")

    profile_dataframe = pd.concat(profiles)
    profile_dataframe = profile_dataframe.reset_index(drop=True)

    return profile_dataframe


=== Content of /home/sam/github/data-driven-investor-platform/data_pipeline/database/database_session.py ===

# Existing imports...
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from common.config import DATABASE_URL
import logging

logger = logging.getLogger(__name__)

# Initialize the database
try:
    engine = create_engine(DATABASE_URL)
    SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
    logger.info("Successfully initialized the database session.")
except Exception as e:
    logger.exception(f"An error occurred while initializing the database: {e}")


=== Content of /home/sam/github/data-driven-investor-platform/data_pipeline/database/models/financial_statements.py ===

from sqlalchemy import Column, String, Integer, Boolean, Date, Sequence, BigInteger
from sqlalchemy.orm import declarative_base

Base = declarative_base()


# SQLAlchemy Models
class Profile(Base):
    __tablename__ = "profiles"
    symbol = Column(String, primary_key=True, index=True)
    companyName = Column(String)
    cik = Column(Integer)
    exchange = Column(String)
    exchangeShortName = Column(String)
    industry = Column(String)
    sector = Column(String)
    country = Column(String)
    ipoDate = Column(Date)
    defaultImage = Column(Boolean)
    isEtf = Column(Boolean)
    isActivelyTrading = Column(Boolean)


class CashFlow(Base):
    __tablename__ = "cashflows2"
    __table_args__ = {"extend_existing": True}

    id = Column(Integer, Sequence("cashflow_id_seq"), primary_key=True, index=True)
    date = Column(String)  # Representing period[Q-DEC] as string
    symbol = Column(String, index=True)
    reportedCurrency = Column(String)
    cik = Column(BigInteger)
    fillingDate = Column(Date)
    acceptedDate = Column(Date)
    calendarYear = Column(BigInteger)
    period = Column(String)

    # Columns changed from Integer to BigInteger
    netIncome = Column(BigInteger)
    depreciationAndAmortization = Column(BigInteger)
    deferredIncomeTax = Column(BigInteger)
    stockBasedCompensation = Column(BigInteger)
    changeInWorkingCapital = Column(BigInteger)
    accountsReceivables = Column(BigInteger)
    inventory = Column(BigInteger)
    accountsPayables = Column(BigInteger)
    otherWorkingCapital = Column(BigInteger)
    otherNonCashItems = Column(BigInteger)
    netCashProvidedByOperatingActivities = Column(BigInteger)
    investmentsInPropertyPlantAndEquipment = Column(BigInteger)
    acquisitionsNet = Column(BigInteger)
    purchasesOfInvestments = Column(BigInteger)
    salesMaturitiesOfInvestments = Column(BigInteger)
    otherInvestingActivites = Column(BigInteger)
    netCashUsedForInvestingActivites = Column(BigInteger)
    debtRepayment = Column(BigInteger)
    commonStockIssued = Column(BigInteger)
    commonStockRepurchased = Column(BigInteger)
    dividendsPaid = Column(BigInteger)
    otherFinancingActivites = Column(BigInteger)
    netCashUsedProvidedByFinancingActivities = Column(BigInteger)
    effectOfForexChangesOnCash = Column(BigInteger)
    netChangeInCash = Column(BigInteger)
    cashAtEndOfPeriod = Column(BigInteger)
    cashAtBeginningOfPeriod = Column(BigInteger)
    operatingCashFlow = Column(BigInteger)
    capitalExpenditure = Column(BigInteger)
    freeCashFlow = Column(BigInteger)

    link = Column(String)
    finalLink = Column(String)


=== Content of /home/sam/github/data-driven-investor-platform/data_pipeline/common/config.py ===

from dotenv import load_dotenv
import os
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

load_dotenv()

try:
    DATABASE_URL = os.getenv("DATABASE_URL")
    FMP_API_KEY = os.getenv("FMP_SECRET_KEY")
    HTTP_PORT = int(os.getenv("HTTP_PORT", 8000))

    if DATABASE_URL is None:
        logger.warning("DATABASE_URL environment variable is missing.")

    if FMP_API_KEY is None:
        logger.warning("FMP_SECRET_KEY environment variable is missing.")

    if HTTP_PORT is None:
        logger.warning("HTTP_PORT environment variable is missing or invalid.")

    logger.info("Successfully loaded environment variables.")
except Exception as e:
    logger.error(f"Failed to load environment variables: {e}")


=== Content of /home/sam/github/data-driven-investor-platform/data_pipeline/common/constants.py ===

MIN_BIGINT = -9223372036854775808
MAX_BIGINT = 9223372036854775807


=== Content of /home/sam/github/data-driven-investor-platform/data_pipeline/fetch_data/fetch_equities.py ===

import financedatabase as fd
from investorkit.investorkit.get_data.base import get_profile, get_financial_statements
from monitoring.prometheus_metrics import (
    EXECUTION_TIME,
    NEW_SYMBOLS,
    SYMBOLS_LENGTH,
    FETCH_PARAMS,
    MISSING_SYMBOLS,
)
from utils.context_manager import session_scope
from utils.process_data import filter_bigint_range
from datetime import datetime
import pandas as pd
import logging

logging.basicConfig(filename="app.log", level=logging.INFO)
logger = logging.getLogger(__name__)
run_id = datetime.now().isoformat()


def store_to_db(df, table_name, engine, SessionLocal):
    try:
        with session_scope(SessionLocal) as session:
            df.to_sql(table_name, con=engine, if_exists="append", index=False)
            session.flush()
        logger.info(f"Stored data into table {table_name}")
    except Exception as e:
        logger.error(f"Failed to store data into table {table_name}. Error: {e}")


@EXECUTION_TIME.time()
def fetch_equity_symbols(country="United States", market="NASDAQ Global Select"):
    try:
        equities = fd.Equities()
        selected_columns = [
            "name",
            "currency",
            "sector",
            "industry_group",
            "industry",
            "exchange",
            "market",
            "market_cap",
        ]
        us_equities = equities.select(country=country)
        df_equities = us_equities[us_equities["market"] == market][selected_columns]
        list_symbols = list(df_equities.index)

        SYMBOLS_LENGTH.labels(run_id=run_id).set(len(list_symbols))
        FETCH_PARAMS.labels(country=country, market=market, run_id=run_id).set(
            len(list_symbols)
        )
        logger.info(
            f"Fetched {len(list_symbols)} equity symbols for {country} - {market}"
        )
        return list_symbols
    except Exception as e:
        logger.error(
            f"Failed to fetch equity symbols for {country} - {market}. Error: {e}"
        )


@EXECUTION_TIME.time()
def get_new_symbols(list_symbols, engine):
    try:
        existing_symbols_query = "SELECT symbol FROM profiles;"
        existing_symbols = pd.read_sql(existing_symbols_query, con=engine)
        new_symbols = list(set(list_symbols) - set(existing_symbols["symbol"].tolist()))
        new_symbols = new_symbols[:20]

        NEW_SYMBOLS.labels(run_id=run_id).inc(len(new_symbols))
        logger.info(f"Identified {len(new_symbols)} new symbols")
        return new_symbols
    except Exception as e:
        logger.error(f"Failed to identify new symbols. Error: {e}")


def fetch_and_store_profiles(engine, api_key, SessionLocal):
    list_symbols = fetch_equity_symbols()
    new_symbols = get_new_symbols(list_symbols, engine)

    if new_symbols:
        df_profiles = get_profile(new_symbols, api_key)

        if not df_profiles.empty:
            missing_symbols = set(new_symbols) - set(df_profiles["symbol"])
            MISSING_SYMBOLS.labels(run_id=run_id).inc(len(missing_symbols))

            list_cols = [
                "symbol",
                "companyName",
                "cik",
                "exchange",
                "exchangeShortName",
                "industry",
                "sector",
                "country",
                "ipoDate",
                "defaultImage",
                "isEtf",
                "isActivelyTrading",
            ]

            df_profiles_filtered = df_profiles[list_cols]
            df_profiles_filtered["ipoDate"].replace("", None, inplace=True)
            df_profiles_filtered["cik"].replace("", None, inplace=True)

            store_to_db(df_profiles_filtered, "profiles", engine, SessionLocal)
        else:
            print("No profiles found for the new symbols.")
            MISSING_SYMBOLS.labels(run_id=run_id).inc(len(new_symbols))


def fetch_and_store_financial_statements(engine, api_key, SessionLocal):
    try:
        query = "SELECT DISTINCT symbol FROM cashflows2;"
        existing_symbols_df = pd.read_sql(query, engine)
        existing_symbols = set(existing_symbols_df["symbol"])

        query = "SELECT * FROM profiles;"
        df_profiles = pd.read_sql(query, engine)

        list_symbols = list(df_profiles["symbol"])
        list_symbols = [
            symbol for symbol in list_symbols if symbol not in existing_symbols
        ]

        chunks = [list_symbols[i : i + 100] for i in range(0, len(list_symbols), 100)]

        for chunk in chunks:
            df, invalid_tickers = get_financial_statements(
                tickers=chunk,
                statement="cashflow",
                api_key=api_key,
                start_date="2000-01-01",
            )

            filtered_df = filter_bigint_range(df)
            store_to_db(filtered_df, "cashflows2", engine, SessionLocal)
            logger.info(f"Stored financial statements for {len(chunk)} symbols.")
    except Exception as e:
        logger.error(
            f"An error occurred while fetching and storing financial statements: {e}"
        )
