/home/sam/github/data-driven-investor-platform
├── backend
│   ├── config
│   ├── db
│   │   ├── db_engine.py
│   │   ├── db_generete_schema_model.py
│   │   ├── db_utils.py
│   │   └── schema_models.py
│   ├── environment.yml
│   ├── main.py
│   ├── monitoring
│   ├── requirements.txt
│   └── tests
│       └── test_db_operations.py
├── custom_tree_and_files_corrected.txt
├── data
├── data_pipeline
│   ├── database
│   │   ├── database_session.py
│   │   ├── models
│   │   │   └── financial_statements.py
│   │   └── utils
│   ├── fetch_data
│   │   └── fetch_equities.py
│   ├── investorkit
│   │   ├── environment.yml
│   │   ├── .gitignore
│   │   ├── investorkit
│   │   │   └── get_data
│   │   │       └── base.py
│   │   ├── LICENSE
│   │   ├── README.md
│   │   └── requirements.txt
│   ├── main.py
│   ├── monitoring
│   │   └── prometheus_metrics.py
│   ├── setup_database.py
│   └── utils
│       ├── config.py
│       ├── constants.py
│       ├── context_manager.py
│       └── process_data.py
├── .env
├── frontend
│   ├── config
│   ├── .gitignore
│   ├── jsconfig.json
│   ├── monitoring
│   ├── package.json
│   ├── package-lock.json
│   ├── README.md
│   └── src
│       ├── App.js
│       ├── assets
│       │   └── profile.jpeg
│       ├── components
│       │   ├── DataGridCustomToolbar.jsx
│       │   ├── FlexBetween.jsx
│       │   ├── Header.jsx
│       │   ├── Navbar.jsx
│       │   └── Sidebar.jsx
│       ├── index.css
│       ├── index.js
│       ├── scenes
│       │   ├── assets
│       │   │   └── index.jsx
│       │   ├── dashboard
│       │   │   └── index.jsx
│       │   └── layout
│       │       └── index.jsx
│       ├── state
│       │   ├── api.js
│       │   └── index.js
│       └── theme.js
├── .gitignore
├── ingestion
├── LICENSE
└── README.md

29 directories, 49 files


=== Content of /home/sam/github/data-driven-investor-platform/data_pipeline/main.py ===

from fetch_data.fetch_equities import (
    fetch_and_store_profiles,
    fetch_and_store_financial_statements,
)
from database.database_session import SessionLocal, engine  # Centralized import
from utils.config import FMP_API_KEY  # Centralized configuration
from prometheus_client import start_http_server
import logging  # Using logging instead of print statements

# Initialize logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

if __name__ == "__main__":
    start_http_server(8000)
    logger.info("HTTP server started on port 8000")

    try:
        fetch_and_store_profiles(engine, FMP_API_KEY, SessionLocal)
        fetch_and_store_financial_statements(engine, FMP_API_KEY, SessionLocal)
    except Exception as e:
        logger.error(f"An error occurred: {e}")


=== Content of /home/sam/github/data-driven-investor-platform/data_pipeline/setup_database.py ===

from sqlalchemy import create_engine
from database.models.financial_statements import Base
from utils.config import DATABASE_URL  # Import from the consolidated config file

engine = create_engine(DATABASE_URL)


def setup_database():
    Base.metadata.create_all(bind=engine)


if __name__ == "__main__":
    setup_database()


=== Content of /home/sam/github/data-driven-investor-platform/data_pipeline/utils/process_data.py ===

import numpy as np
from utils.constants import MIN_BIGINT, MAX_BIGINT


def filter_bigint_range(df):
    min_bigint = -MIN_BIGINT
    max_bigint = MAX_BIGINT

    for col in df.select_dtypes(include=[np.number]).columns:
        mask = (df[col] >= min_bigint) & (df[col] <= max_bigint)
        df = df[mask]

    return df


=== Content of /home/sam/github/data-driven-investor-platform/data_pipeline/utils/config.py ===

from dotenv import load_dotenv
import os

load_dotenv()

DATABASE_URL = os.getenv("DATABASE_URL")
FMP_API_KEY = os.getenv("FMP_SECRET_KEY")


=== Content of /home/sam/github/data-driven-investor-platform/data_pipeline/utils/context_manager.py ===

from contextlib import contextmanager
from sqlalchemy.orm import sessionmaker


@contextmanager
def session_scope(SessionLocal):
    """Provide a transactional scope around a series of operations."""
    session = SessionLocal()
    try:
        yield session
        session.commit()
    except:
        session.rollback()
        raise
    finally:
        session.close()


=== Content of /home/sam/github/data-driven-investor-platform/data_pipeline/utils/constants.py ===

MIN_BIGINT = -9223372036854775808
MAX_BIGINT = 9223372036854775807


=== Content of /home/sam/github/data-driven-investor-platform/data_pipeline/monitoring/prometheus_metrics.py ===

from prometheus_client import Summary, Counter, Gauge

EXECUTION_TIME = Summary("function_execution_seconds", "Time spent processing.")
NEW_SYMBOLS = Counter(
    "new_symbols_fetched", "Number of new symbols fetched.", ["run_id"]
)
SYMBOLS_LENGTH = Gauge(
    "symbols_length", "Length of the list of symbols fetched.", ["run_id"]
)
TOTAL_RECORDS = Gauge(
    "total_records", "Total number of records in the profiles table.", ["run_id"]
)
FETCH_PARAMS = Gauge(
    "fetch_params",
    "Parameters passed to fetch_equity_symbols",
    ["country", "market", "run_id"],
)
MISSING_SYMBOLS = Counter(
    "missing_symbols_fetched", "Number of missing new symbols.", ["run_id"]
)


=== Content of /home/sam/github/data-driven-investor-platform/data_pipeline/investorkit/investorkit/get_data/base.py ===

from typing import Union, List, Tuple
import pandas as pd
import numpy as np
import logging

# Initialize logging
logging.basicConfig(level=logging.WARNING)

try:
    from tqdm import tqdm

    ENABLE_TQDM = True
except ImportError:
    ENABLE_TQDM = False

### Useful for debug
# tickers=list(df['symbol'])
# statement="cashflow"
# api_key=FMP_API_KEY
# quarter = True
# start_date="2000-01-01"
# end_date=None
# rounding = 4
# progress_bar = True


def get_financial_statements(
    tickers: Union[str, List[str]],
    statement: str = "",
    api_key: str = "",
    quarter: bool = True,
    start_date: Union[str, None] = None,
    end_date: Union[str, None] = None,
    rounding: Union[int, None] = 4,
    progress_bar: bool = True,
) -> Tuple[pd.DataFrame, List[str]]:
    """
    Retrieves financial statements for one or multiple companies and returns a DataFrame.

    Args:
        tickers: List of company tickers.
        statement: Type of financial statement ("balance", "income", or "cashflow").
        api_key: API key for financial data provider.
        quarter: Whether to retrieve quarterly data.
        start_date: Start date to filter data.
        end_date: End date to filter data.
        rounding: Rounding precision.
        progress_bar: Show progress bar for more than 10 tickers.

    Returns:
        Tuple containing the DataFrame of financial statements and a list of invalid tickers.

    Example:

        df, invalid_tickers = get_financial_statements(
            tickers=["AAPL", "META"],
            statement="cashflow",
            api_key="your_api_key_here",
            start_date="2000-01-01"
        )
    """

    # Ensure tickers is a list
    if not isinstance(tickers, (list, str)):
        raise ValueError(f"Invalid type for tickers: {type(tickers)}")

    ticker_list = tickers if isinstance(tickers, list) else [tickers]

    statement_to_location = {
        "balance": "balance-sheet-statement",
        "income": "income-statement",
        "cashflow": "cash-flow-statement",
    }

    location = statement_to_location.get(statement)
    if location is None:
        raise ValueError(
            "Invalid statement type. Choose 'balance', 'income', or 'cashflow'."
        )

    period = "quarter" if quarter else "annual"

    financial_statement_dict = {}
    invalid_tickers = []

    ticker_iterator = (
        tqdm(ticker_list, desc=f"Obtaining {statement} data")
        if ENABLE_TQDM & progress_bar
        else ticker_list
    )

    for ticker in ticker_iterator:
        url = f"https://financialmodelingprep.com/api/v3/{location}/{ticker}?period={period}&apikey={api_key}"

        try:
            financial_statement = pd.read_json(url)
            if financial_statement.empty:
                logging.warning(f"Received empty data for {ticker}")
                invalid_tickers.append(ticker)
                continue

        except Exception as error:
            logging.warning(f"Could not fetch data for {ticker}. Error: {error}")
            invalid_tickers.append(ticker)
            continue

        # Convert date to appropriate format
        date_col = "date" if quarter else "calendarYear"
        freq = "Q" if quarter else "Y"
        financial_statement[date_col] = pd.to_datetime(
            financial_statement[date_col].astype(str)
        ).dt.to_period(freq)

        financial_statement_dict[ticker] = financial_statement

    if not financial_statement_dict:
        return pd.DataFrame(), invalid_tickers

    financial_statement_total = pd.concat(financial_statement_dict)

    financial_statement_total.reset_index(drop=True, inplace=True)
    financial_statement_total = financial_statement_total.drop_duplicates().reset_index(
        drop=True
    )

    if start_date or end_date:
        mask = True
        if start_date:
            mask &= financial_statement_total["date"] >= start_date
        if end_date:
            mask &= financial_statement_total["date"] <= end_date
        financial_statement_total = financial_statement_total[mask]

    financial_statement_total["date"] = financial_statement_total["date"].astype(str)
    return financial_statement_total, invalid_tickers


def get_profile(tickers, api_key):
    """
    Description
    ----
    Gives information about the profile of a company which includes
    i.a. beta, company description, industry, and sector.

    Parameters
    ----
    tickers : list or str
        The company tickers (e.g., "AAPL" or ["AAPL", "GOOGL"]).
    api_key : str
        The API Key obtained from Financial Modeling Prep.

    Returns
    ----
    pd.DataFrame
        Data with variables in rows and tickers in columns.
    """
    # Ensure tickers is a list
    if not isinstance(tickers, (list, str)):
        raise ValueError(f"Type for the tickers ({type(tickers)}) variable is invalid.")

    tickers = tickers if isinstance(tickers, list) else [tickers]

    profiles = {}
    for ticker in tqdm(tickers):
        try:
            data = pd.read_json(
                f"https://financialmodelingprep.com/api/v3/profile/{ticker}?apikey={api_key}"
            )
            profiles[ticker] = data
        except Exception as error:
            print(f"Warning: Could not fetch data for {ticker}. Error: {error}")

    profile_dataframe = pd.concat(profiles)
    profile_dataframe = profile_dataframe.reset_index(drop=True)

    return profile_dataframe


=== Content of /home/sam/github/data-driven-investor-platform/data_pipeline/database/database_session.py ===

from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from utils.config import DATABASE_URL

engine = create_engine(DATABASE_URL)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)


=== Content of /home/sam/github/data-driven-investor-platform/data_pipeline/database/models/financial_statements.py ===

from sqlalchemy import Column, String, Integer, Boolean, Date, Sequence, BigInteger
from sqlalchemy.orm import declarative_base

Base = declarative_base()


# SQLAlchemy Models
class Profile(Base):
    __tablename__ = "profiles"
    symbol = Column(String, primary_key=True, index=True)
    companyName = Column(String)
    cik = Column(Integer)
    exchange = Column(String)
    exchangeShortName = Column(String)
    industry = Column(String)
    sector = Column(String)
    country = Column(String)
    ipoDate = Column(Date)
    defaultImage = Column(Boolean)
    isEtf = Column(Boolean)
    isActivelyTrading = Column(Boolean)


class CashFlow(Base):
    __tablename__ = "cashflows2"
    __table_args__ = {"extend_existing": True}

    id = Column(Integer, Sequence("cashflow_id_seq"), primary_key=True, index=True)
    date = Column(String)  # Representing period[Q-DEC] as string
    symbol = Column(String, index=True)
    reportedCurrency = Column(String)
    cik = Column(BigInteger)
    fillingDate = Column(Date)
    acceptedDate = Column(Date)
    calendarYear = Column(BigInteger)
    period = Column(String)

    # Columns changed from Integer to BigInteger
    netIncome = Column(BigInteger)
    depreciationAndAmortization = Column(BigInteger)
    deferredIncomeTax = Column(BigInteger)
    stockBasedCompensation = Column(BigInteger)
    changeInWorkingCapital = Column(BigInteger)
    accountsReceivables = Column(BigInteger)
    inventory = Column(BigInteger)
    accountsPayables = Column(BigInteger)
    otherWorkingCapital = Column(BigInteger)
    otherNonCashItems = Column(BigInteger)
    netCashProvidedByOperatingActivities = Column(BigInteger)
    investmentsInPropertyPlantAndEquipment = Column(BigInteger)
    acquisitionsNet = Column(BigInteger)
    purchasesOfInvestments = Column(BigInteger)
    salesMaturitiesOfInvestments = Column(BigInteger)
    otherInvestingActivites = Column(BigInteger)
    netCashUsedForInvestingActivites = Column(BigInteger)
    debtRepayment = Column(BigInteger)
    commonStockIssued = Column(BigInteger)
    commonStockRepurchased = Column(BigInteger)
    dividendsPaid = Column(BigInteger)
    otherFinancingActivites = Column(BigInteger)
    netCashUsedProvidedByFinancingActivities = Column(BigInteger)
    effectOfForexChangesOnCash = Column(BigInteger)
    netChangeInCash = Column(BigInteger)
    cashAtEndOfPeriod = Column(BigInteger)
    cashAtBeginningOfPeriod = Column(BigInteger)
    operatingCashFlow = Column(BigInteger)
    capitalExpenditure = Column(BigInteger)
    freeCashFlow = Column(BigInteger)

    link = Column(String)
    finalLink = Column(String)


=== Content of /home/sam/github/data-driven-investor-platform/data_pipeline/fetch_data/fetch_equities.py ===

import financedatabase as fd
from investorkit.investorkit.get_data.base import get_profile, get_financial_statements
from monitoring.prometheus_metrics import (
    EXECUTION_TIME,
    NEW_SYMBOLS,
    SYMBOLS_LENGTH,
    FETCH_PARAMS,
    MISSING_SYMBOLS,
)
from utils.context_manager import session_scope
from utils.process_data import filter_bigint_range
from datetime import datetime
import pandas as pd

run_id = datetime.now().isoformat()


def store_to_db(df, table_name, engine, SessionLocal):
    with session_scope(SessionLocal) as session:
        df.to_sql(table_name, con=engine, if_exists="append", index=False)
        session.flush()


@EXECUTION_TIME.time()
def fetch_equity_symbols(country="United States", market="NASDAQ Global Select"):
    equities = fd.Equities()
    selected_columns = [
        "name",
        "currency",
        "sector",
        "industry_group",
        "industry",
        "exchange",
        "market",
        "market_cap",
    ]
    us_equities = equities.select(country=country)
    df_equities = us_equities[us_equities["market"] == market][selected_columns]
    list_symbols = list(df_equities.index)

    SYMBOLS_LENGTH.labels(run_id=run_id).set(len(list_symbols))
    FETCH_PARAMS.labels(country=country, market=market, run_id=run_id).set(
        len(list_symbols)
    )

    return list_symbols


@EXECUTION_TIME.time()
def get_new_symbols(list_symbols, engine):
    existing_symbols_query = "SELECT symbol FROM profiles;"
    existing_symbols = pd.read_sql(existing_symbols_query, con=engine)
    new_symbols = list(set(list_symbols) - set(existing_symbols["symbol"].tolist()))
    new_symbols = new_symbols[:20]

    NEW_SYMBOLS.labels(run_id=run_id).inc(len(new_symbols))

    return new_symbols


def fetch_and_store_profiles(engine, api_key, SessionLocal):
    list_symbols = fetch_equity_symbols()
    new_symbols = get_new_symbols(list_symbols, engine)

    if new_symbols:
        df_profiles = get_profile(new_symbols, api_key)

        if not df_profiles.empty:
            missing_symbols = set(new_symbols) - set(df_profiles["symbol"])
            MISSING_SYMBOLS.labels(run_id=run_id).inc(len(missing_symbols))

            list_cols = [
                "symbol",
                "companyName",
                "cik",
                "exchange",
                "exchangeShortName",
                "industry",
                "sector",
                "country",
                "ipoDate",
                "defaultImage",
                "isEtf",
                "isActivelyTrading",
            ]

            df_profiles_filtered = df_profiles[list_cols]
            df_profiles_filtered["ipoDate"].replace("", None, inplace=True)
            df_profiles_filtered["cik"].replace("", None, inplace=True)

            store_to_db(df_profiles_filtered, "profiles", engine, SessionLocal)
        else:
            print("No profiles found for the new symbols.")
            MISSING_SYMBOLS.labels(run_id=run_id).inc(len(new_symbols))


def fetch_and_store_financial_statements(engine, api_key, SessionLocal):
    query = "SELECT DISTINCT symbol FROM cashflows2;"
    existing_symbols_df = pd.read_sql(query, engine)
    existing_symbols = set(existing_symbols_df["symbol"])

    query = "SELECT * FROM profiles;"
    df_profiles = pd.read_sql(query, engine)

    list_symbols = list(df_profiles["symbol"])
    list_symbols = [symbol for symbol in list_symbols if symbol not in existing_symbols]

    chunks = [list_symbols[i : i + 100] for i in range(0, len(list_symbols), 100)]

    for chunk in chunks:
        df, invalid_tickers = get_financial_statements(
            tickers=chunk,
            statement="cashflow",
            api_key=api_key,
            start_date="2000-01-01",
        )

        filtered_df = filter_bigint_range(df)
        store_to_db(filtered_df, "cashflows2", engine, SessionLocal)
